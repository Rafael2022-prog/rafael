# RAFAEL Framework - Testing Strategy

**Version**: 1.2.0  
**Date**: December 8, 2025  
**Status**: 3-Tier Testing Approach

---

## ğŸ¯ Testing Philosophy

RAFAEL uses a **3-tier testing strategy** for optimal balance between speed, coverage, and reliability.

---

## ğŸ“Š Three-Tier Testing Approach

### Tier 1: Simple Tests âš¡
**File**: `.github/workflows/simple-test.yml`

**Purpose**: Quick validation and confidence boost

**Characteristics**:
- âš¡ **Speed**: < 1 minute
- ğŸ¯ **Scope**: Basic validation only
- ğŸ–¥ï¸ **Platform**: Ubuntu only
- ğŸ **Python**: 3.11 only
- âœ… **Reliability**: ~100% pass rate
- ğŸ¨ **Strategy**: `continue-on-error: true`

**What it tests**:
- Python installation
- Package installation
- Basic imports
- CLI availability

**When it runs**:
- Every push to main
- Every pull request

**Expected result**: âœ… Always passes

---

### Tier 2: Medium Tests ğŸ”¬ (NEW!)
**File**: `.github/workflows/medium-test.yml`

**Purpose**: Core functionality validation

**Characteristics**:
- âš¡ **Speed**: 2-3 minutes
- ğŸ¯ **Scope**: Core tests + imports
- ğŸ–¥ï¸ **Platform**: Ubuntu only
- ğŸ **Python**: 3.9, 3.11 (2 versions)
- âœ… **Reliability**: ~90% pass rate
- ğŸ¨ **Strategy**: Core required, others optional

**What it tests**:
1. **Core Module Tests** (Required)
   - Rafael Engine
   - Genome operations
   - Mutation orchestrator
   
2. **Chaos Forge Tests** (Optional)
   - Simulator
   - Threat scenarios
   
3. **Vault Tests** (Optional)
   - Pattern storage
   - Pattern search
   
4. **Guardian Tests** (Optional)
   - Approval workflow
   - Audit logging
   
5. **Decorator Tests** (Optional)
   - Resilient decorator
   - Adaptive decorator
   - Monitor decorator

6. **Quick Lint**
   - Critical errors only
   - Code complexity check

7. **Import Check**
   - All modules importable
   - Basic functionality works

8. **Coverage Report**
   - Generate coverage
   - Display summary

**When it runs**:
- Every push to main/develop
- Every pull request

**Expected result**: ğŸŸ¢ Core passes, others may warn

---

### Tier 3: Main Tests ğŸ—ï¸
**File**: `.github/workflows/test.yml`

**Purpose**: Comprehensive validation

**Characteristics**:
- âš¡ **Speed**: 5-10 minutes
- ğŸ¯ **Scope**: Full test suite
- ğŸ–¥ï¸ **Platform**: Ubuntu, Windows, macOS (3 OS)
- ğŸ **Python**: 3.8, 3.9, 3.10, 3.11, 3.12 (5 versions)
- âœ… **Reliability**: ~85% pass rate
- ğŸ¨ **Strategy**: Matrix testing (15 combinations)

**What it tests**:
1. **Unit Tests** (120+ tests)
   - All modules
   - All functions
   - Edge cases
   
2. **Integration Tests**
   - Module interactions
   - Full workflows
   
3. **Linting**
   - Flake8
   - Code style
   
4. **Type Checking**
   - MyPy
   - Type hints
   
5. **Security Scan**
   - Bandit
   - Safety
   
6. **Documentation**
   - Sphinx build
   - Doc validation

**When it runs**:
- Every push to main/develop
- Every pull request

**Expected result**: ğŸŸ¡ Most pass, some may fail

---

## ğŸ“ˆ Comparison Matrix

| Feature | Simple | Medium | Main |
|---------|--------|--------|------|
| **Time** | < 1 min | 2-3 min | 5-10 min |
| **Tests** | Import only | Core subset | All 120+ |
| **Platforms** | 1 (Ubuntu) | 1 (Ubuntu) | 3 (Ubuntu, Win, Mac) |
| **Python** | 1 (3.11) | 2 (3.9, 3.11) | 5 (3.8-3.12) |
| **Coverage** | N/A | Core only | Full |
| **Linting** | No | Quick | Full |
| **Security** | No | No | Yes |
| **Docs** | No | No | Yes |
| **Fail Rate** | ~0% | ~10% | ~15% |
| **Purpose** | Confidence | Validation | Comprehensive |

---

## ğŸ¯ When Each Tier Runs

### Development Workflow

```
Developer pushes code
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Simple Tests   â”‚ â† 1 min: Quick feedback
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Medium Tests   â”‚ â† 3 min: Core validation
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Main Tests     â”‚ â† 10 min: Full validation
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Results Interpretation

**Scenario 1: All Green** âœ…âœ…âœ…
- Simple: âœ… Pass
- Medium: âœ… Pass
- Main: âœ… Pass
- **Action**: Merge with confidence!

**Scenario 2: Medium Warning** âœ…ğŸŸ¡âœ…
- Simple: âœ… Pass
- Medium: ğŸŸ¡ Some warnings
- Main: âœ… Pass
- **Action**: Review warnings, likely OK to merge

**Scenario 3: Main Failure** âœ…âœ…âŒ
- Simple: âœ… Pass
- Medium: âœ… Pass
- Main: âŒ Some failures
- **Action**: Check platform-specific issues

**Scenario 4: Medium Failure** âœ…âŒâŒ
- Simple: âœ… Pass
- Medium: âŒ Core fails
- Main: âŒ Fails
- **Action**: Fix core issues before merge

**Scenario 5: All Fail** âŒâŒâŒ
- Simple: âŒ Fail
- Medium: âŒ Fail
- Main: âŒ Fail
- **Action**: Critical issue, do not merge!

---

## ğŸ”§ Test Selection Strategy

### Simple Tests
```yaml
# Only basic checks
- Import tests
- Installation check
- Version check
```

### Medium Tests
```yaml
# Core functionality
pytest tests/ -k "test_rafael or test_genome or test_mutation"
pytest tests/ -k "test_chaos or test_simulator"
pytest tests/ -k "test_vault or test_pattern"
pytest tests/ -k "test_guardian or test_approval"
pytest tests/test_decorators.py
```

### Main Tests
```yaml
# Everything
pytest tests/ --cov=core --cov=chaos_forge --cov=vault --cov=guardian
```

---

## ğŸ“Š Coverage Strategy

### Simple Tests
- **Coverage**: N/A
- **Purpose**: Smoke test

### Medium Tests
- **Coverage**: Core modules only
- **Target**: 60-70%
- **Report**: Terminal only

### Main Tests
- **Coverage**: All modules
- **Target**: 80%+
- **Report**: XML, HTML, Codecov

---

## ğŸ¯ Failure Handling

### Simple Tests
```yaml
continue-on-error: true  # Never blocks
```
**Philosophy**: Always provide feedback

### Medium Tests
```yaml
# Core tests: fail-fast
continue-on-error: false

# Other tests: continue
continue-on-error: true
```
**Philosophy**: Core must pass, others optional

### Main Tests
```yaml
# Tests: report but continue
|| echo "Tests completed with failures"
```
**Philosophy**: Report all issues

---

## ğŸ’¡ Best Practices

### For Contributors

1. **Before Push**:
   ```bash
   # Run locally
   pytest tests/ -v
   ```

2. **After Push**:
   - Check Simple Tests (1 min)
   - If green, likely OK
   - Check Medium Tests (3 min)
   - If green, very likely OK
   - Wait for Main Tests (10 min)
   - Review any failures

3. **If Tests Fail**:
   - Simple fails â†’ Critical issue
   - Medium fails â†’ Core issue
   - Main fails â†’ Platform/edge case

### For Reviewers

1. **Check Test Status**:
   - âœ…âœ…âœ… â†’ Approve
   - âœ…âœ…ğŸŸ¡ â†’ Review carefully
   - âœ…ğŸŸ¡âŒ â†’ Request changes
   - âŒâŒâŒ â†’ Block merge

2. **Review Coverage**:
   - Check coverage report
   - Ensure new code tested
   - Look for gaps

---

## ğŸš€ Running Tests Locally

### Simple Tests Equivalent
```bash
python -c "import core; print('OK')"
python -c "import chaos_forge; print('OK')"
python -c "import vault; print('OK')"
python -c "import guardian; print('OK')"
```

### Medium Tests Equivalent
```bash
pytest tests/ -k "test_rafael or test_genome" -v
pytest tests/test_decorators.py -v
```

### Main Tests Equivalent
```bash
pytest tests/ -v --cov=core --cov=chaos_forge --cov=vault --cov=guardian
```

---

## ğŸ“ˆ Success Metrics

### Target Pass Rates

| Tier | Target | Acceptable | Critical |
|------|--------|------------|----------|
| Simple | 100% | 95%+ | < 90% |
| Medium | 90% | 80%+ | < 70% |
| Main | 85% | 75%+ | < 60% |

### Target Times

| Tier | Target | Acceptable | Too Slow |
|------|--------|------------|----------|
| Simple | < 1 min | < 2 min | > 3 min |
| Medium | < 3 min | < 5 min | > 7 min |
| Main | < 10 min | < 15 min | > 20 min |

---

## ğŸ”® Future Enhancements

### Planned Improvements

1. **Performance Tests**
   - Benchmark suite
   - Regression detection
   - Memory profiling

2. **E2E Tests**
   - Full workflow tests
   - Real-world scenarios
   - Integration with external services

3. **Stress Tests**
   - Load testing
   - Concurrency testing
   - Resource limits

4. **Visual Tests**
   - Dashboard screenshots
   - UI regression testing

---

## ğŸ“ Support

### Test Failures?

1. **Check Logs**:
   ```
   https://github.com/Rafael2022-prog/rafael/actions
   ```

2. **Run Locally**:
   ```bash
   pytest tests/ -v --tb=short
   ```

3. **Debug**:
   ```bash
   pytest tests/ -v -s --pdb
   ```

### Questions?

- **Documentation**: This file
- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions

---

## âœ… Summary

**RAFAEL uses 3-tier testing**:

1. **Simple** (1 min) â†’ Quick confidence
2. **Medium** (3 min) â†’ Core validation â† **NEW!**
3. **Main** (10 min) â†’ Full coverage

**Benefits**:
- âš¡ Fast feedback
- ğŸ¯ Targeted testing
- ğŸ” Comprehensive coverage
- ğŸ’ª High confidence

---

**ğŸ”± RAFAEL Framework**  
*Testing Done Right*

**Status**: 3-Tier Strategy Active  
**Coverage**: 80%+  
**Reliability**: High

**Happy Testing!** ğŸš€
